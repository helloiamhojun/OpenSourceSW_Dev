# 대용량 실시간 데이터 처리를 위한 Apache Kafka 분석

## 1. 선정 배경 및 도입 필요성

- 기존 시스템의 문제점:
    - 과거 기업들의 시스템은 소스 애플리케이션(Source)과 타겟 애플리케이션(Target)이 직접 연결되는 **Point-to-Point** 방식이었음.
    - 웹사이트와 인프라에서 발생하는 **대량의 이벤트 데이터**를 Hadoop(배치 처리)과 실시간 처리 시스템으로 동시에 보내는 '람다 아키텍처(Lambda Architecture)'를 구현해야 했다.
    - **N:M 연결의 복잡성:** 서비스가 커질수록 연결 고리가 기하급수적으로 늘어나, 시스템 간의 의존성(Dependency)과 결합도(Coupling)가 지나치게 높아짐 (이른바 '스파게티 아키텍처').
    - 데이터 유실 위험: 수신 시스템에 장애가 발생하면 데이터가 그대로 유실됨.
    - 핵심은 **'실시간(Real-time)'** 처리에 있었는데, 당시에는 이를 감당할 적절한 솔루션이 없었다.
- 기존 솔루션의 한계:
    - **배치 시스템용 도구:** 실시간 처리에 부적합했고, 데이터를 받는 쪽(Consumer)에 부담을 주는 'Push 방식'이었다.
    - **전통적인 메시지 큐 (ActiveMQ, RabbitMQ 등):** 트랜잭션이나 메시지 추적 같은 기능은 훌륭했지만, LinkedIn이 원하는 **대용량 데이터 수집(Ingestion)** 목적에는 기능이 너무 과하고(Overkill) 속도가 느렸습니다.
- 결론: 데이터가 없으면 화려한 머신러닝 알고리즘도 무용지물이다. LinkedIn은 데이터를 소스에서 시스템으로 안정적으로 옮기는 '백본(Backbone)'이 필요했고, 이를 위해 Kafka를 만들었다.
- kafka 도입의 필요성
    - **중앙집중화:** 모든 데이터의 흐름을 중앙의 Kafka로 모으고, 각 서비스는 Kafka와만 연결하는 구조로 단순화.
    - **느슨한 결합(Loose Coupling):** 데이터를 생산하는 측(Producer)은 누가 데이터를 가져가는지 알 필요가 없음.
    - **버퍼링 역할:** 갑작스러운 트래픽 폭주(Spike) 시에도 Kafka가 데이터를 쌓아두(Buffering)므로, 뒤단의 시스템이 죽지 않고 안정적으로 처리 가능.

## 2. 기술적 아키텍처 분석

- 주요 구성 요소:
    - 로그(Log) 데이터 구조:
        - 여기서 말하는 로그는 애플리케이션의 에러 로그가 아니다. '시간 순서대로 데이터가 계속 뒤에 붙는(Append-only) 구조'를 말한다. 이는 데이터베이스의 핵심 원리와 같다.
        - DB는 변경 사항을 로그에 적고 그것으로 테이블을 만든다. Kafka는 이 로그 자체를 토픽(Topic)으로 관리합니다.
        - 예시(쇼핑 카트):
            - 로그: "상품 A 담기" → "상품 B 담기" → "상품 A 삭제" → "결제”
            - 이 로그를 읽어가서 현재 장바구니 상태("상품 B만 있음, 결제 대기 중")를 만들어 낸다.
            - Kafka는 데이터를 오랫동안(설정에 따라 영구적으로) 보관하므로, 언제든 **과거 시점으로 되감아서(Rewind)** 다시 처리하거나 새로운 알고리즘을 테스트해볼 수 있다.
    - **Broker (브로커):** 카프카 서버. 데이터를 저장하고 관리하는 주체. 보통 3대 이상의 클러스터로 구성하여 안정성 확보.
    - **Topic (토픽):** 데이터가 들어가는 '방' (예: `order_log`, `user_signup`). RDB의 테이블과 유사한 개념
    - **Partition (파티션):** 하나의 토픽을 여러 개로 쪼갠 단위. 병렬 처리를 가능하게 하여 처리 속도를 높이는 핵심 기술.
    - **Offset (오프셋):** 파티션 내에서 데이터의 위치를 나타내는 고유 번호. 컨슈머가 "어디까지 읽었는지"를 기억하는 용도.
- 핵심 기술 원리:
    - **Sequential I/O (순차 입출력):** 디스크는 랜덤 접근은 느리지만 순차 접근은 매우 빠름. Kafka는 데이터를 뒤에 붙이는(Append-only) 방식만 사용하여 하드디스크를 쓰면서도 메모리급의 속도를 냄.
    - **Zero-Copy:** 운영체제의 커널 레벨에서 데이터를 바로 네트워크로 쏘는 기술을 사용하여 CPU 사용량을 최소화함.
- kafka가 ‘하지 않는’ 것 (성능 최적화의 비결)
    - **개별 메시지 ID가 없음:** 대신 오프셋(Offset)이라는 위치 번호로만 관리한다.
    - **소비자(Consumer) 추적 안 함:** 누가 뭘 읽었는지는 Kafka가 신경 쓰지 않고, 소비자가 직접 기억한다.
    - **인덱스 없음 & 삭제 없음:** 랜덤 액세스를 지원하지 않고 순차적으로만 읽으며, 데이터는 삭제하지 않고 정해진 기간 동안 보관한다.
    - **Zero-Copy:** 데이터를 사용자 메모리 공간에 복사하지 않고, 커널 레벨에서 바로 네트워크로 쏘는 기술을 사용하여 매우 빠르다.

## 3. 현업 활용 사례

- 1) LinkedIn (개발사):
    - **활용:** 사용자 활동 추적 (클릭, 페이지 뷰, 검색 등) 및 운영 지표 모니터링.
    - **성과:** 하루 1조 건 이상의 메시지를 처리하며, 배치 처리(Batch)와 실시간 처리(Stream)를 통합함.
- 2) Netflix (넷플릭스):
    - **적용 시스템:** Keystone Pipeline (통합 이벤트 발행, 수집, 라우팅 인프라)
    - **주요 기술:** Apache Kafka, Apache Samza, ZooKeeper, AWS EC2
    - **핵심 주제:** 일 7,000억 건 이상의 메시지를 처리하는 초대규모 클라우드 환경에서의 Kafka 아키텍처 및 장애 대응 전략
    - **도입 배경 및 문제점 (Challenges)**
        - **초대용량 트래픽:** 하루 평균 7,000억 건(2016년 기준) 이상의 메시지를 처리해야 하는 환경에서 AWS EC2 비용 효율성을 고려하면서 "데이터 무손실(Zero Loss)"을 달성하는 것은 현실적으로 불가능에 가까움.
        - **클라우드 인프라의 불안정성:** 클라우드 인스턴스는 언제든 종료될 수 있고 네트워크 일시 장애가 빈번하여, ZooKeeper와 같은 상태 저장(Stateful) 서비스 운영에 큰 도전이 됨.
        - **'Outlier' 브로커 문제:** 특정 브로커의 반응 속도 저하가 발생하면 프로듀서(Producer)의 버퍼가 고갈되어 애플리케이션 전체 성능 저하 및 메시지 유실로 이어지는 연쇄 장애 발생.
    - **핵심 해결 방안 (Solutions)**
        - **Kafka 클러스터 역할 분리 (Fronting vs Consumer)**
            - **방식:** Kafka 클러스터를 데이터 수집 전용인 **Fronting Kafka**와 소비를 위한 **Consumer Kafka**로 물리적으로 분리.
            - **구현:**
                - **Fronting Kafka:** 모든 프로듀서(앱)로부터 데이터를 수집하는 역할만 수행하며, 부하 예측이 어렵지 않도록 직접적인 데이터 소비(Consume)를 차단.
                - **Consumer Kafka:** 실시간 소비가 필요한 일부 토픽만 라우팅하여 별도 구성.
            - **효과:** 데이터 유입(Ingest)과 소비(Consume) 부하를 격리하여 전체 파이프라인의 안정성 확보.
        - **가용성 중심의 프로듀서(Producer) 설정 및 운영**
            - **전략:** 데이터의 완벽한 보존보다 서비스 가용성(Availability)을 최우선으로 설정.
            - **설정:** `acks=1` (리더만 확인), `block.on.buffer.full=false` (버퍼가 차면 메시지 드랍) 설정을 통해 Kafka 장애가 넷플릭스 서비스 사용자 경험에 영향을 주지 않도록 차단.
            - **결과:** 약 0.01% 미만의 데이터 손실률을 허용하는 대신, 비용 효율적이고 중단 없는 서비스 환경 구축.
        - **자동화된 장애 조치(Failover) 시스템 구축**
            - **방식:** 주(Primary) 클러스터 장애 시 즉시 트래픽을 전환할 수 있는 **Cold Standby 클러스터**를 상시 대기.
            - **구현:** 장애 감지 시 예비 클러스터 사이즈를 자동으로 확장(Scale-up)하고, 애플리케이션 재배포 없이 런타임 설정 변경만으로 프로듀서 트래픽을 예비 클러스터로 전환.
            - **효과:** 대규모 장애 상황에서도 5분 이내에 복구 가능하며, 무중단으로 Kafka 버전 업그레이드나 유지보수 작업 수행 가능.
        - **운영 효율화를 위한 자체 도구 개발**
            - **Sticky Partitioner:** 프로듀서가 일정 시간 동안 한 파티션에만 데이터를 보내도록 하여 배치 효율을 높이고 브로커 부하 감소.
            - **Rack-Aware Replica Assignment:** AWS 가용 영역(AZ) 장애에 대비해 복제본(Replica)을 서로 다른 AZ에 강제로 분산 배치 (오픈소스 기여).
        - **도입 효과 (Results)**
            - **압도적 확장성:** 36개 클러스터, 4,000대 이상의 브로커를 통해 일 수천억 건의 데이터 처리 가능.
            - **장애 격리:** 하나의 거대 클러스터 대신 작은 단위의 여러 클러스터로 쪼개어 운영(Sharding)함으로써 장애 영향 범위(Blast Radius) 최소화.
            - **운영 유연성:** 서비스 중단 없이 인프라 교체 및 유지보수가 가능한 아키텍처 완성.
- 3) 우아한형제들 (배달의 민족):
    - **적용 부서:** 딜리버리서비스팀 (배민배달 중계 시스템 담당)
    - **주요 기술:** Apache Kafka, Kafka Connect (Debezium), Kafka Streams, AWS S3/Athena
    - **핵심 주제:** 분산 시스템 환경에서 하루 100만 건 이상의 주문/배달 트래픽을 안정적으로 처리하고 데이터 정합성을 보장하기 위한 아키텍처 구축
    - **도입 배경 및 문제점 (Challenges)**
        - **대규모 트래픽 및 복잡성:** 하루 100만 건 이상의 주문이 발생하며, 주문 접수부터 배달 완료까지 수많은 상태 변경 이벤트가 발생함.
        - **데이터 정합성 이슈:** 마이크로서비스(MSA) 환경에서 DB 업데이트와 이벤트 발행(Message Publishing)이 별도로 동작할 경우, 시스템 장애 시 DB에는 데이터가 저장되었으나 이벤트가 발행되지 않아 데이터 불일치(Inconsistency)가 발생할 위험 존재.
        - **이벤트 순서 보장 필요:** '배차' 후 '픽업'과 같이 배달 과정의 순서가 뒤바뀌면 비즈니스 로직에 치명적인 오류 발생.
        - **실시간 분석 요구:** 운영 DB에 부하를 주지 않으면서 실시간 배달 현황을 모니터링하고 데이터를 분석할 수 있는 환경 필요.
    - **핵심 해결 방안 (Solutions)**
        
        **(1) Transactional Outbox Pattern 적용 (데이터 정합성 확보)**
        
        - **방식:** 비즈니스 로직 처리 시 DB에 데이터를 저장함과 동시에 'Outbox'라는 별도 테이블에 발행할 메시지를 함께 저장(동일 트랜잭션으로 묶음).
        - **구현:** **CDC(Change Data Capture) 도구인 Debezium**을 활용하여 Outbox 테이블의 변경 사항(binlog)을 감지하고, 이를 카프카 메시지로 자동 발행.
        - **효과:** DB 트래픽과 메시지 발행이 원자적(Atomic)으로 처리되어, 장애가 발생하더라도 데이터 누락이나 불일치가 원천적으로 방지됨.
        
        **(2) Kafka를 이벤트 버스로 활용 (분산 캐시 동기화)**
        
        - **방식:** 분산된 서버 간의 설정 값이나 인메모리 데이터를 동기화하기 위해 카프카를 이벤트 버스로 사용.
        - **구현:** 특정 서버에서 설정이 변경되면 카프카로 이벤트를 전송(Broadcast)하고, 다른 모든 서버가 이를 구독하여 자신의 메모리 상태를 최신화.
        - **효과:** 서버 재배포 없이 동적으로 운영 설정을 변경하고 모든 서버에 즉시 전파 가능.
        
        **(3) Kafka Streams 및 데이터 파이프라인 구축 (실시간 분석)**
        
        - **방식:** 운영 로직과 분석 로직을 물리적으로 분리.
        - **구현:**
            - **Kafka Streams:** 실시간으로 유입되는 배달 이벤트를 집계하여 현재 배달 상태(배차 대기 등)를 대시보드(Grafana)로 시각화.
            - **S3 & Athena:** 발생한 모든 이벤트를 S3에 적재(Sink Connector)하여 운영 DB 부하 없이 대용량 이력 데이터 분석 수행.
    - **도입 효과 (Results)**
        - **시스템 신뢰성 향상:** 네트워크 장애나 서버 다운 시에도 이벤트 누락이 "0건"으로 방지되며, 데이터 순서 보장을 통해 배달 프로세스 오류 최소화.
        - **운영 효율성 증대:** 실시간 모니터링 체계를 통해 배달 지연 등의 이슈를 즉각 파악하고 대응 가능.
        - **유연한 확장성:** 비즈니스 서비스와 분석 서비스가 카프카를 통해 느슨하게 결합(Decoupling)되어, 상호 영향 없이 각각 독립적으로 시스템을 확장 가능.
- **기업명:** 카카오 (Kakao)
    - **적용 부서:** MessageQueue TF (인프라팀)
    - **주요 기술:** Apache Kafka, RabbitMQ, Kafka Manager (CMAK), Kminion, Burrow
    - **핵심 주제:** 개별 서비스팀마다 운영하던 메시지 큐를 '공용 플랫폼'으로 통합하여 운영 리소스를 절감하고 안정성을 확보한 사례
    - **도입 배경 및 문제점 (Challenges)**
        - **운영 비효율성:** 2016년 이전까지 각 서비스팀이 Kafka와 RabbitMQ를 개별적으로 구축 및 운영하여 인프라 비용 낭비와 관리 리소스 중복 발생.
        - **전문성 부족에 따른 위험:** 개발자가 비즈니스 로직 외에 메시지 큐 인프라까지 직접 관리하다 보니, 메시지 유실이나 장애 처리에 대한 전문적 대응이 어려움.
        - **대규모 트래픽 증가:** 서비스 규모가 커짐에 따라 대용량 로그 트래픽(Kafka)과 복잡한 라우팅이 필요한 메시징(RabbitMQ) 수요가 동시에 급증.
    - **핵심 해결 방안 (Solutions)**
        - **공용(Shared) 클러스터 구축 및 중앙 집중 관리**
            - **방식:** 서비스팀별 개별 구축 방식에서 벗어나, 전사 공용 클러스터를 구축하여 인프라팀(TF)에서 통합 운영.
            - **구현:**
                - **Kafka:** 대용량 로그 트래픽 처리를 위한 메인 파이프라인으로 구성.
                - **RabbitMQ:** 복잡한 라우팅이나 신뢰성 있는 메시지 전달이 필요한 경우를 위해 별도 제공.
            - **효과:** 개발팀은 인프라 운영 부담 없이 서비스 개발에만 집중 가능하며, 중앙에서 전문적인 모니터링 및 장애 대응 지원.
        - **운영 자동화 및 가시성 확보 (Monitoring & Visibility)**
            - **모니터링 체계:**
                - **로그:** NIFI + Elasticsearch + 사내 알람 시스템(WatchTower) 연동.
                - **메트릭:** Kminion, Burrow(오픈소스)를 자체 Kubernetes 환경에서 무중단 운영하며, Prometheus + Grafana로 시각화.
            - **사용자 대시보드 제공:**
                - **Kafka Dashboard:** 토픽별 인입량, 컨슈머(Consumer) 상태(Lag), 파티션 불균형 등을 개발자가 직접 확인 가능.
                - **Consumer Status:** 그룹 상태를 OK/WARN/STOP/ERROR 4단계로 시각화하여 장애 발생 시 즉각 인지 가능하도록 지원.
            - **Self-Service 가능한 웹/API 플랫폼 구축**
                - **방식:** 운영자에게 티켓으로 요청하는 방식을 넘어, 개발자가 직접 토픽 생성/관리할 수 있는 Kafka Web 및 API 제공.
                - **기능:** 부서별 클러스터 정보 확인, 전용 클러스터 생성 요청, 토픽/파티션 설정 변경, 알람 설정 등을 웹 UI에서 수행.
        - **도입 효과 (Results)**
            - **운영 리소스 최적화:** 중복된 인프라 구축 비용 절감 및 전문 운영 조직을 통한 안정성 확보.
            - **장애 대응 속도 향상:** Consumer Utilization(0~1 지표) 및 Lag 모니터링을 통해 메시지 처리 지연이나 컨슈머 장애를 실시간으로 파악 및 조치 가능.
            - **유연한 인프라 제공:** 일반적인 용도는 '공용 클러스터'를 사용하고, 특수한 설정(Config)이나 보안이 필요한 경우 '전용 클러스터'를 제공하는 하이브리드 지원 체계 완성.

## 4. 마이크로서비스(MSA) 지원

Kafka는 빅데이터뿐만 아니라 마이크로서비스 환경에서도 중요한 역할을 한다.

- **이벤트 소싱(Event Sourcing) & CQRS:** 서비스 간의 결합도를 낮추기 위해 사용된다.
- **로그 컴팩션(Log Compaction):** 오래된 데이터를 지우는 대신, '최신 상태'만 남겨두는 기능이다. 이를 통해 서비스가 죽었다 살아나도 Kafka의 로그만 읽으면 최신 상태를 복구할 수 있다.

## 5. 유사 기술 비교 분석

- 전통적 브로커 (RabbitMQ, ActiveMQ 등):
    - 복잡한 라우팅, 메시지 처리 확인(Ack), 다양한 프로토콜 지원이 필요할 때 적합히다.
    - 요청-응답(Request-Response) 방식이나 메시지 수명(TTL) 관리가 필요하면 기존 MQ가 낫다.
- kafka:
    - **대용량 데이터의 스트리밍**과 **영구 보존**이 필요할 때 압도적으로 유리합니다.

| **비교 항목** | **Apache Kafka** | **RabbitMQ** |
| --- | --- | --- |
| **설계 철학** | **대용량 데이터 스트리밍** (로그 중심) | **복잡한 메시지 라우팅** (작업 중심) |
| **메시지 보관** | **영구 저장** (디스크에 설정 기간 보관) | 소비 즉시 **삭제** (메모리 중심) |
| **소비 방식** | **Pull 방식** (컨슈머가 능력껏 가져감) | **Push 방식** (브로커가 컨슈머에게 밀어넣음) |
| **처리량 (속도)** | 초당 수십만~수백만 건 (압도적) | 초당 수만 건 수준 |
| **확장성** | 수평 확장(Scale-out)이 매우 쉬움 | 수평 확장이 상대적으로 어려움 |
- 분석 결론:
    - 모든 경우에 맞는 도구는 없다. 하지만 시스템의 모든 이벤트를 수집하여 ‘Source of Truth’으로 삼고 싶다면 Kafka가 최고의 선택이다. 
    단순한 작업 큐나 복잡한 라우팅이 필요하면 RabbitMQ가 낫지만, **대규모 트래픽 처리와 데이터 보존**이 중요하다면 Kafka가 표준임.

## 6. 성과 및 한계점

- 성과:
    - 시스템 간 결합도를 낮추어 마이크로서비스 아키텍처(MSA)의 성공적인 정착을 도움.
    - 장애 발생 시 데이터를 보존하고 있어 복구(Replay)가 가능함.
- 한계점:
    - **운영 복잡도:** 과거에는 Zookeeper라는 별도 코디네이터 시스템이 필수여서 설치와 운영이 매우 까다로웠음 (최근 KRaft 모드로 개선 중).
    - **실시간성:** 'Real-time'이라고 하지만, 엄밀히 말하면 아주 짧은 주기의 배치(Micro-batch) 처리에 가까워 금융 거래 같은 초저지연(Latency)이 필요한 곳에는 부적합할 수 있음.
    - **과도한 스펙:** 하루 트래픽이 적은 소규모 서비스에는 도입 비용이 더 큼 (Over-engineering).

### 출처:

[https://www.linkedin.com/pulse/kafkas-origin-story-linkedin-tanvir-ahmed](https://www.linkedin.com/pulse/kafkas-origin-story-linkedin-tanvir-ahmed)

[https://techblog.woowahan.com/17386/](https://techblog.woowahan.com/17386/)

[https://netflixtechblog.com/kafka-inside-keystone-pipeline-dd5aeabaf6bb](https://netflixtechblog.com/kafka-inside-keystone-pipeline-dd5aeabaf6bb)

[https://tech.kakao.com/posts/485](https://tech.kakao.com/posts/485)

# 구글에 Kafka architecture diagram 검색해서 나오는 사진 자료 써주셨으면 좋겠습니다!